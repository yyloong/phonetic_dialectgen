# GlowTTS

type: Post
status: Draft
date: 2025/07/10

### ç½‘ç»œç»“æ„

- ä»£ç 
    
    ```
    GlowTTS(
      (encoder): Encoder(
        (emb): Embedding(129, 192)
        (prenet): ResidualConv1dLayerNormBlock(
          (conv_layers): ModuleList(
            (0-2): 3 x Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))
          )
          (norm_layers): ModuleList(
            (0-2): 3 x LayerNorm()
          )
          (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
        )
        (encoder): RelativePositionTransformer(
          (dropout): Dropout(p=0.1, inplace=False)
          (attn_layers): ModuleList(
            (0-5): 6 x RelativePositionMultiHeadAttention(
              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (norm_layers_1): ModuleList(
            (0-5): 6 x LayerNorm()
          )
          (ffn_layers): ModuleList(
            (0-5): 6 x FeedForwardNetwork(
              (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))
              (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (norm_layers_2): ModuleList(
            (0-5): 6 x LayerNorm()
          )
        )
        (proj_m): Conv1d(192, 80, kernel_size=(1,), stride=(1,))
        (duration_predictor): DurationPredictor(
          (drop): Dropout(p=0.1, inplace=False)
          (conv_1): Conv1d(192, 256, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm_1): LayerNorm()
          (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm_2): LayerNorm()
          (proj): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
        )
      )
      (decoder): Decoder(
        (flows): ModuleList(
          (0): ActNorm()
          (1): InvConvNear()
          (2): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (3): ActNorm()
          (4): InvConvNear()
          (5): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (6): ActNorm()
          (7): InvConvNear()
          (8): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (9): ActNorm()
          (10): InvConvNear()
          (11): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (12): ActNorm()
          (13): InvConvNear()
          (14): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (15): ActNorm()
          (16): InvConvNear()
          (17): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (18): ActNorm()
          (19): InvConvNear()
          (20): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (21): ActNorm()
          (22): InvConvNear()
          (23): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (24): ActNorm()
          (25): InvConvNear()
          (26): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (27): ActNorm()
          (28): InvConvNear()
          (29): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (30): ActNorm()
          (31): InvConvNear()
          (32): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
          (33): ActNorm()
          (34): InvConvNear()
          (35): CouplingBlock(
            (start): ParametrizedConv1d(
              80, 192, kernel_size=(1,), stride=(1,)
              (parametrizations): ModuleDict(
                (weight): ParametrizationList(
                  (0): _WeightNorm()
                )
              )
            )
            (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))
            (wn): WN(
              (in_layers): ModuleList(
                (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))
              )
              (res_skip_layers): ModuleList(
                (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))
                (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))
              )
              (dropout): Dropout(p=0.05, inplace=False)
            )
          )
        )
      )
    )
    ```
    

å‚è€ƒçš„ CoquiTTS å¯¹äº GlowTTS çš„å®ç°ä»£ç 

ä»¥ä¸‹æ˜¯ä¸€äº›ä¸»è¦æ–‡ä»¶

/home/u-wuhc/.local/share/tts/

/home/u-wuhc/TTS/TTS/utils/synthesizer.py

/home/u-wuhc/TTS/TTS/utils/audio/processor.py

/home/u-wuhc/TTS/TTS/tts/models/glow_tts.py

/home/u-wuhc/TTS/TTS/tts/configs/glow_tts_config.py

/home/u-wuhc/TTS/recipes/ljspeech/glow_tts/train_glowtts.py

/home/u-wuhc/TTS/recipes/ljspeech/glow_tts/test.py

/home/u-wuhc/TTS/TTS/config/shared_configs.py

/home/u-wuhc/TTS/toMel.py

### TODO

- [ ]  Text Tokenizer
- [ ]  Losses æ˜¯ä»€ä¹ˆ
- [ ]  è®­ç»ƒè¿‡ç¨‹
- [ ]  Dataloader (train)
- [ ]  è®ºæ–‡
- [ ]  load checkpoint
- [ ]  save model

- å¦‚ä½•å¤„ç†é•¿åº¦ä¸åŒçš„ x è¾“å…¥
    
    x : text IDs
    
    åœ¨ Encoder ä¸­å¤„ç†
    
    ## GlowTTS å¦‚ä½•å¤„ç†é•¿åº¦ä¸åŒçš„ x è¾“å…¥
    
    ### ğŸ¯ **1. æ‰¹é‡å¤„ç†ä¸åŒé•¿åº¦çš„æ–‡æœ¬**
    
    GlowTTS ä½¿ç”¨ **padding + mask** çš„ç­–ç•¥å¤„ç†ä¸åŒé•¿åº¦çš„æ–‡æœ¬è¾“å…¥ï¼š
    
    ```python
    # ç¤ºä¾‹ï¼šä¸åŒé•¿åº¦çš„æ–‡æœ¬åºåˆ—
    batch = [
        "Hello world",      # é•¿åº¦ = 11
        "Hi",              # é•¿åº¦ = 2
        "How are you?"     # é•¿åº¦ = 12
    ]
    
    # è½¬æ¢ä¸º token IDs åï¼š
    x = torch.tensor([
        [23, 15, 12, 12, 24, 0, 28, 24, 18, 12, 14, 0, 0],  # padding åˆ°æœ€å¤§é•¿åº¦
        [23, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],          # padding åˆ°æœ€å¤§é•¿åº¦
        [23, 24, 28, 0, 1, 18, 15, 0, 25, 24, 21, 0, 0]    # padding åˆ°æœ€å¤§é•¿åº¦
    ])  # shape: [3, 13] - æ‰¹æ¬¡å¤§å°=3, æœ€å¤§é•¿åº¦=13
    
    x_lengths = torch.tensor([11, 2, 12])  # å„åºåˆ—çš„å®é™…é•¿åº¦
    
    ```
    
    ### ğŸ¯ **2. ç¼–ç å™¨ä¸­çš„ Mask å¤„ç†**
    
    ```python
    def forward(self, x, x_lengths, y, y_lengths=None):
        # ç¼–ç å™¨å¤„ç†æ–‡æœ¬ï¼Œè¿”å› mask
        o_mean, o_log_scale, o_dur_log, x_mask = self.encoder(x, x_lengths, g=None)
        #                                                                    â†‘
        #                                                              æ–‡æœ¬åºåˆ—çš„ mask
    
        # x_mask çš„ä½œç”¨ï¼š
        # x_mask[0] = [1,1,1,1,1,1,1,1,1,1,1,0,0]  # å‰11ä¸ªæœ‰æ•ˆï¼Œå2ä¸ªæ— æ•ˆ
        # x_mask[1] = [1,1,0,0,0,0,0,0,0,0,0,0,0]  # å‰2ä¸ªæœ‰æ•ˆï¼Œå11ä¸ªæ— æ•ˆ
        # x_mask[2] = [1,1,1,1,1,1,1,1,1,1,1,1,0]  # å‰12ä¸ªæœ‰æ•ˆï¼Œå1ä¸ªæ— æ•ˆ
    
    ```
    
    ### ğŸ¯ **3. å‚æ•° `num_chars` çš„å«ä¹‰**
    
    `num_chars` æ˜¯ **è¯æ±‡è¡¨å¤§å°**ï¼ˆvocabulary sizeï¼‰ï¼Œè¡¨ç¤ºæ¨¡å‹èƒ½è¯†åˆ«çš„ä¸åŒå­—ç¬¦/tokençš„æ•°é‡ï¼š
    
    ```python
    config = GlowTTSConfig(num_chars=100, out_channels=80)
    #                      â†‘
    #                  è¯æ±‡è¡¨å¤§å° = 100ä¸ªä¸åŒçš„å­—ç¬¦/token
    
    # æ„å‘³ç€ï¼š
    # - æ–‡æœ¬ä¼šè¢«è½¬æ¢ä¸º 0-99 èŒƒå›´å†…çš„æ•´æ•° token
    # - ç¼–ç å™¨çš„åµŒå…¥å±‚ç»´åº¦ä¸º [num_chars, embedding_dim]
    # - ä¾‹å¦‚ï¼š'a'â†’1, 'b'â†’2, 'c'â†’3, ..., ' 'â†’0, '<PAD>'â†’99
    
    ```
    
    ### ğŸ¯ **4. ç¼–ç å™¨ä¸­çš„å¤„ç†æµç¨‹**
    
    ```python
    class Encoder:
        def __init__(self, num_chars, ...):
            # å­—ç¬¦åµŒå…¥å±‚
            self.emb = nn.Embedding(num_chars, hidden_channels)
            #                       â†‘           â†‘
            #                  è¯æ±‡è¡¨å¤§å°     åµŒå…¥ç»´åº¦
    
        def forward(self, x, x_lengths, g=None):
            # 1. å­—ç¬¦åµŒå…¥
            x = self.emb(x)  # [B, T_en] â†’ [B, T_en, hidden_channels]
    
            # 2. ç”Ÿæˆåºåˆ—mask
            x_mask = torch.unsqueeze(sequence_mask(x_lengths, x.size(1)), 1)
            #                                     â†‘           â†‘
            #                               å®é™…é•¿åº¦     æœ€å¤§é•¿åº¦
    
            # 3. åº”ç”¨maskåˆ°åµŒå…¥
            x = x * x_mask  # å°†paddingéƒ¨åˆ†ç½®é›¶
    
            # 4. åç»­çš„ç¼–ç å™¨å±‚å¤„ç†...
            return o_mean, o_log_scale, o_dur_log, x_mask
    
    ```
    
    ### ğŸ¯ **5. å®é™…åº”ç”¨ç¤ºä¾‹**
    
    ```python
    # ä¸­æ–‡TTSçš„è¯æ±‡è¡¨å¯èƒ½åŒ…å«ï¼š
    vocabulary = {
        '<PAD>': 0,    # å¡«å……token
        '<SOS>': 1,    # å¼€å§‹token
        '<EOS>': 2,    # ç»“æŸtoken
        'ä½ ': 3,
        'å¥½': 4,
        'ä¸–': 5,
        'ç•Œ': 6,
        'ï¼Œ': 7,
        'ã€‚': 8,
        # ... æ›´å¤šå­—ç¬¦
    }
    
    # å¦‚æœè¯æ±‡è¡¨æœ‰1000ä¸ªå­—ç¬¦ï¼Œåˆ™ï¼š
    config = GlowTTSConfig(num_chars=1000, ...)
    
    # æ–‡æœ¬ "ä½ å¥½ä¸–ç•Œ" ä¼šè¢«è½¬æ¢ä¸ºï¼š
    text = "ä½ å¥½ä¸–ç•Œ"
    tokens = [3, 4, 5, 6]  # å¯¹åº”çš„token IDs
    x = torch.tensor([tokens])  # [1, 4]
    x_lengths = torch.tensor([4])  # å®é™…é•¿åº¦
    
    ```
    
    ### ğŸ¯ **6. é•¿åº¦å¤„ç†çš„å®Œæ•´æµç¨‹**
    
    ```python
    def process_batch(texts):
        # 1. æ–‡æœ¬è½¬token
        tokens_list = [text_to_tokens(text) for text in texts]
    
        # 2. è·å–é•¿åº¦ä¿¡æ¯
        lengths = [len(tokens) for tokens in tokens_list]
        max_length = max(lengths)
    
        # 3. Paddingåˆ°ç»Ÿä¸€é•¿åº¦
        padded_tokens = []
        for tokens in tokens_list:
            padded = tokens + [0] * (max_length - len(tokens))  # ç”¨0å¡«å……
            padded_tokens.append(padded)
    
        # 4. è½¬æ¢ä¸ºå¼ é‡
        x = torch.tensor(padded_tokens)  # [B, max_length]
        x_lengths = torch.tensor(lengths)  # [B]
    
        return x, x_lengths
    
    ```
    
    ### ğŸ¯ **æ€»ç»“**
    
    - **`num_chars`**: è¯æ±‡è¡¨å¤§å°ï¼Œå®šä¹‰äº†æ¨¡å‹èƒ½å¤„ç†çš„ä¸åŒå­—ç¬¦/tokenæ•°é‡
    - **é•¿åº¦å¤„ç†**: é€šè¿‡paddingç»Ÿä¸€æ‰¹æ¬¡å†…çš„åºåˆ—é•¿åº¦ï¼Œç”¨maskæ ‡è®°æœ‰æ•ˆéƒ¨åˆ†
    - **æ ¸å¿ƒæ€æƒ³**: ç‰©ç†ä¸Šç»Ÿä¸€é•¿åº¦ï¼ˆä¾¿äºå¹¶è¡Œè®¡ç®—ï¼‰ï¼Œé€»è¾‘ä¸Šä¿æŒåŸå§‹é•¿åº¦ï¼ˆç¡®ä¿æ­£ç¡®å¤„ç†ï¼‰
    
    è¿™ç§è®¾è®¡ä½¿å¾—GlowTTSèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†ä»»æ„é•¿åº¦çš„æ–‡æœ¬è¾“å…¥ï¼
    
- forward å’Œ inference å‡½æ•°çš„åŒºåˆ«
    
    forward ç”¨äºè®­ç»ƒ
    
    inference ç”¨äºæ¨ç†
    
    y_lengths æ˜¯ mel-spectrogram çš„çœŸå®é•¿åº¦
    
    ### ğŸ¯ **å…³é”®åŒºåˆ«**ï¼š
    
    - **`y_lengths`** æ¯ä¸ªæ ·æœ¬çš„**å®é™…æœ‰æ•ˆé•¿åº¦**
    - **`T_de`** æ‰¹æ¬¡ä¸­çš„**æœ€å¤§é•¿åº¦**ï¼ˆç”¨äºå¼ é‡å¡«å……ï¼‰
    
    ### ğŸ” **è¯¦ç»†è§£é‡Š**ï¼š
    
    ```python
    # å‡è®¾æœ‰ä¸€ä¸ªæ‰¹æ¬¡åŒ…å«3ä¸ªæ ·æœ¬ï¼š
    batch = [
        sample1: å®é™…é•¿åº¦ = 80 å¸§
        sample2: å®é™…é•¿åº¦ = 120 å¸§
        sample3: å®é™…é•¿åº¦ = 100 å¸§
    ]
    
    # é‚£ä¹ˆï¼š
    y_lengths = torch.tensor([80, 120, 100])  # å„æ ·æœ¬çš„å®é™…é•¿åº¦
    T_de = 120  # æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦ï¼Œç”¨äºå¼ é‡å¡«å……
    
    # æœ€ç»ˆçš„å¼ é‡å½¢çŠ¶ï¼š
    y.shape = [3, 120, 80]  # [B, T_de, C_mel]
    #           â†‘   â†‘    â†‘
    #           |   |    æ¢…å°”é¢‘è°±ç»´åº¦
    #           |   æœ€å¤§é•¿åº¦ï¼ˆå¡«å……åï¼‰
    #           æ‰¹æ¬¡å¤§å°
    
    ```
    
    ### ğŸ¯ **åœ¨ forward() ä¸­çš„å¤„ç†**ï¼š
    
    ```python
    def forward(self, x, x_lengths, y, y_lengths=None):
        # è¾“å…¥ï¼šy.shape = [B, T_de, C_mel]
        # è¾“å…¥ï¼šy_lengths = [å®é™…é•¿åº¦1, å®é™…é•¿åº¦2, ...]
    
        # 1. è½¬æ¢ç»´åº¦
        y = y.transpose(1, 2)  # [B, C_mel, T_de]
        y_max_length = y.size(2)  # T_de = æœ€å¤§é•¿åº¦
    
        # 2. é¢„å¤„ç†ï¼ˆå¯èƒ½ä¼šè°ƒæ•´é•¿åº¦ï¼‰
        y, y_lengths, y_max_length, attn = self.preprocess(y, y_lengths, y_max_length, None)
    
        # 3. åˆ›å»ºæ©ç ï¼ˆå…³é”®ï¼ï¼‰
        y_mask = torch.unsqueeze(sequence_mask(y_lengths, y_max_length), 1).to(x_mask.dtype)
        #                                     â†‘           â†‘
        #                              å®é™…é•¿åº¦    æœ€å¤§é•¿åº¦
    
    ```
    
    ### ğŸ¯ **ä¸ºä»€ä¹ˆéœ€è¦ `y_lengths`ï¼Ÿ**
    
    ```python
    # ç¤ºä¾‹ï¼šsequence_mask çš„ä½œç”¨
    y_lengths = torch.tensor([80, 120, 100])
    y_max_length = 120
    
    mask = sequence_mask(y_lengths, y_max_length)
    # ç»“æœï¼š
    # mask[0] = [1,1,1,...,1,0,0,...,0]  # å‰80ä¸ªä¸º1ï¼Œå40ä¸ªä¸º0
    #            â†â€”â€” 80 â€”â€”â†’ â†â€”â€” 40 â€”â€”â†’
    # mask[1] = [1,1,1,...,1]            # å…¨120ä¸ªä¸º1
    # mask[2] = [1,1,1,...,1,0,0,...,0]  # å‰100ä¸ªä¸º1ï¼Œå20ä¸ªä¸º0
    #            â†â€”â€” 100 â€”â€”â†’ â†â€”â€” 20 â€”â€”â†’
    
    ```
    
    ### ğŸ¯ **æ€»ç»“**ï¼š
    
    - **`T_de`**: å¼ é‡çš„ç‰©ç†ç»´åº¦ï¼ˆæœ€å¤§é•¿åº¦ï¼‰
    - **`y_lengths`**: æ¯ä¸ªæ ·æœ¬çš„é€»è¾‘é•¿åº¦ï¼ˆå®é™…æœ‰æ•ˆé•¿åº¦ï¼‰
    - **ä½œç”¨**: `y_lengths` ç”¨äºç”Ÿæˆæ©ç ï¼Œç¡®ä¿æ¨¡å‹åªå¤„ç†æœ‰æ•ˆæ•°æ®ï¼Œå¿½ç•¥å¡«å……éƒ¨åˆ†
    
    æ‰€ä»¥ `y_lengths` ä¸æ˜¯ `T_de` çš„å€¼ï¼Œè€Œæ˜¯æ¯ä¸ªæ ·æœ¬åœ¨ `T_de` ç»´åº¦ä¸Šçš„**æœ‰æ•ˆé•¿åº¦**ï¼
    

### inference è¿‡ç¨‹

![image.png](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/image.png)

**æ–‡æœ¬ -> ç¼–ç å™¨ -> (å‡å€¼Î¼, æ—¶é•¿d) -> æ‰©å±•å¯¹é½ -> é‡‡æ ·z -> è§£ç å™¨ -> æ¢…å°”é¢‘è°±å›¾**

- ä¸»è¦æµç¨‹
    
    æˆ‘ä»¬å¯ä»¥å‚è€ƒè®ºæ–‡ä¸­çš„ **Figure 1(b) An abstract diagram of the inference procedure** æ¥é€æ­¥åˆ†è§£ã€‚
    
    ### æ ¸å¿ƒæ€æƒ³
    
    Glow-TTSåœ¨å‰å‘æ¨ç†æ—¶ï¼Œå®Œå…¨æ˜¯ **éè‡ªå›å½’ï¼ˆnon-autoregressiveï¼‰**çš„ã€‚è¿™æ„å‘³ç€å®ƒä¸€æ¬¡æ€§ç”Ÿæˆæ•´ä¸ªæ¢…å°”é¢‘è°±å›¾ï¼Œè€Œä¸æ˜¯åƒTacotron 2é‚£æ ·ä¸€å¸§ä¸€å¸§åœ°ç”Ÿæˆã€‚è¿™ä¸ªè¿‡ç¨‹ä¸ä¾èµ–äºå‰ä¸€æ—¶åˆ»çš„è¾“å‡ºï¼Œå› æ­¤å¯ä»¥å®Œå…¨å¹¶è¡ŒåŒ–ï¼Œé€Ÿåº¦æå¿«ã€‚
    
    æœ€é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œåœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨çš„ **MASï¼ˆMonotonic Alignment Searchï¼‰ç®—æ³•åœ¨æ¨ç†æ—¶å®Œå…¨ä¸ä½¿ç”¨**ã€‚MASçš„ä½œç”¨æ˜¯ä¸ºè®­ç»ƒæ‰¾åˆ°æ–‡æœ¬å’Œè¯­éŸ³ä¹‹é—´æœ€å¯èƒ½çš„å¯¹é½å…³ç³»ï¼Œå¹¶ç”¨è¿™ä¸ªå…³ç³»æ¥è®­ç»ƒ**æ—¶é•¿é¢„æµ‹å™¨ï¼ˆDuration Predictorï¼‰**ã€‚ä¸€æ—¦æ—¶é•¿é¢„æµ‹å™¨è®­ç»ƒå¥½äº†ï¼Œæ¨ç†æ—¶å°±åªä¾èµ–å®ƒæ¥ç¡®å®šå¯¹é½ã€‚
    
    ### æ¨ç†æµç¨‹è¯¦è§£ (Step-by-Step)
    
    ### æ­¥éª¤ 1: æ–‡æœ¬ç¼–ç  (Encoder)
    
    1. **è¾“å…¥**: ä¸€æ®µæ–‡æœ¬åºåˆ—ï¼Œé€šå¸¸ä¼šé¢„å¤„ç†æˆéŸ³ç´ ï¼ˆphonemesï¼‰åºåˆ—ï¼Œä¾‹å¦‚ "hello world" -> `[h, É™, l, oÊŠ, w, ÉœË, l, d]`ã€‚ç„¶åé€šè¿‡ tokenizer å°†æ¯ä¸ªå¤„ç†ä¸ºä¸€ä¸ªæ•´æ•°ã€‚
    2. **ç»„ä»¶**: **æ–‡æœ¬ç¼–ç å™¨ (Encoder)**ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºTransformerçš„ç»“æ„ã€‚
    3. **æ“ä½œ**: ç¼–ç å™¨æ¥æ”¶éŸ³ç´ åºåˆ—ï¼Œå¹¶é€šè¿‡å¤šå±‚è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å’Œå‰é¦ˆç½‘ç»œè¿›è¡Œå¤„ç†ã€‚
    4. **è¾“å‡º**:
        - **éšè—è¡¨ç¤º (Hidden Representations)**: ä¸ºæ¯ä¸ªè¾“å…¥çš„éŸ³ç´ ç”Ÿæˆä¸€ä¸ªéšè—çŠ¶æ€å‘é‡ `h`ã€‚
        - **å…ˆéªŒåˆ†å¸ƒå‚æ•° (Prior Distribution Statistics)**: ä»éšè—çŠ¶æ€`h`é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆå›¾ä¸­çš„`Project`ï¼‰é¢„æµ‹å‡ºå…ˆéªŒåˆ†å¸ƒï¼ˆä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼‰çš„**å‡å€¼ `Î¼` å’Œæ ‡å‡†å·® `Ïƒ`**ã€‚æ‰€ä»¥ï¼Œå¯¹äºæ¯ä¸ªè¾“å…¥éŸ³ç´ ï¼Œæˆ‘ä»¬éƒ½æœ‰å¯¹åº”çš„ `Î¼_i` å’Œ `Ïƒ_i`ã€‚
    
    ### æ­¥éª¤ 2: æ—¶é•¿é¢„æµ‹ (Duration Predictor)
    
    1. **è¾“å…¥**: æ–‡æœ¬ç¼–ç å™¨è¾“å‡ºçš„éšè—è¡¨ç¤º `h`ã€‚ï¼ˆæ³¨æ„ï¼šè®ºæ–‡æåˆ°åœ¨è®­ç»ƒæ—¶é•¿é¢„æµ‹å™¨æ—¶ï¼Œä¼šä½¿ç”¨`stop_gradient`æ¥é˜²æ­¢å…¶æ¢¯åº¦å½±å“ç¼–ç å™¨çš„è®­ç»ƒï¼Œä½†è¿™åœ¨æ¨ç†æ—¶æ²¡æœ‰å½±å“ï¼‰ã€‚
    2. **ç»„ä»¶**: **æ—¶é•¿é¢„æµ‹å™¨ (Duration Predictor)**ã€‚
    3. **æ“ä½œ**: è¯¥æ¨¡å—é¢„æµ‹æ¯ä¸ªè¾“å…¥éŸ³ç´ åº”è¯¥æŒç»­å¤šé•¿æ—¶é—´ï¼Œå³å¯¹åº”å¤šå°‘ä¸ªæ¢…å°”é¢‘è°±å›¾çš„å¸§ï¼ˆframesï¼‰ã€‚
    4. **è¾“å‡º**: ä¸€ä¸ªæ—¶é•¿åºåˆ— `d = (d_1, d_2, ..., d_T_text)`ã€‚`d_i` æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºç¬¬`i`ä¸ªéŸ³ç´ å¯¹åº”çš„æ—¶é•¿ã€‚
    
    ### æ­¥éª¤ 3: å¯¹é½æ‰©å±•/ä¸Šé‡‡æ · (Alignment Expansion)
    
    è¿™æ˜¯å°†æ–‡æœ¬åŸŸçš„ä¿¡æ¯æ˜ å°„åˆ°è¯­éŸ³åŸŸçš„å…³é”®ä¸€æ­¥ï¼Œä¹Ÿæ˜¯å–ä»£è®­ç»ƒæ—¶MASç®—æ³•çš„ä¸€æ­¥ã€‚
    
    1. **è¾“å…¥**:
        - æ¥è‡ª**æ­¥éª¤1**çš„å…ˆéªŒåˆ†å¸ƒå‚æ•°åºåˆ— `(Î¼_1, Ïƒ_1), (Î¼_2, Ïƒ_2), ...`
        - æ¥è‡ª**æ­¥éª¤2**çš„é¢„æµ‹æ—¶é•¿åºåˆ— `d = (d_1, d_2, ...)`
    2. **æ“ä½œ**:
        - é¦–å…ˆï¼Œå°†æµ®ç‚¹æ•°çš„æ—¶é•¿`d_i`è½¬æ¢ä¸ºæ•´æ•°ã€‚åœ¨Figure 1(b)ä¸­ï¼Œè¿™ä¸€æ­¥è¢«æ ‡è®°ä¸º `Ceil`ï¼Œè¡¨ç¤ºå‘ä¸Šå–æ•´ã€‚è¿™ç¡®ä¿äº†æ¯ä¸ªéŸ³ç´ è‡³å°‘å¯¹åº”ä¸€å¸§ï¼Œé¿å…äº†ä¿¡æ¯ä¸¢å¤±ã€‚
        - ç„¶åï¼Œæ ¹æ®æ•´æ•°æ—¶é•¿ `d'_i = ceil(d_i)`ï¼Œå°†æ¯ä¸ªéŸ³ç´ å¯¹åº”çš„ `Î¼_i` å’Œ `Ïƒ_i` **é‡å¤** `d'_i` æ¬¡ã€‚
        - ä¾‹å¦‚ï¼Œå¦‚æœéŸ³ç´  "h" çš„é¢„æµ‹æ—¶é•¿æ˜¯ `2.3`ï¼ˆå‘ä¸Šå–æ•´ä¸º3ï¼‰ï¼Œé‚£ä¹ˆå°±å°† "h" å¯¹åº”çš„ `Î¼_h` å’Œ `Ïƒ_h` å¤åˆ¶3éã€‚
    3. **è¾“å‡º**: ä¸¤ä¸ªè¢«"æ‹‰ä¼¸"æˆ–"æ‰©å±•"äº†çš„åºåˆ—ï¼Œ`Î¼_expanded` å’Œ `Ïƒ_expanded`ã€‚å®ƒä»¬çš„æ€»é•¿åº¦ `T_mel` ç­‰äºæ‰€æœ‰éŸ³ç´ æ—¶é•¿çš„æ€»å’Œï¼ˆ`T_mel = Î£ d'_i`ï¼‰ï¼Œè¿™ä¸ªé•¿åº¦å°±æ˜¯æœ€ç»ˆè¦ç”Ÿæˆçš„æ¢…å°”é¢‘è°±å›¾çš„æ—¶é—´æ­¥é•¿ã€‚
    
    ### æ­¥éª¤ 4: é‡‡æ ·ç”Ÿæˆéšå˜é‡ (Latent Variable Generation)
    
    1. **è¾“å…¥**: æ‰©å±•åçš„å‡å€¼åºåˆ— `Î¼_expanded`ã€‚
    2. **æ“ä½œ**: ä»å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·ç”Ÿæˆéšå˜é‡ `z`ã€‚è¿™ä¸ªè¿‡ç¨‹éå¸¸ç®€å•ï¼š
        - é¦–å…ˆï¼Œç”Ÿæˆä¸€ä¸ªä¸`Î¼_expanded`åŒæ ·å¤§å°çš„éšæœºå™ªå£° `Îµ`ï¼Œè¯¥å™ªå£°ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒ `N(0, I)` ä¸­é‡‡æ ·ã€‚
        - ç„¶åï¼Œæ ¹æ®å…¬å¼ `z = Î¼ + Îµ * T` è®¡ç®—éšå˜é‡ `z`ã€‚
            - `Î¼` å°±æ˜¯ `Î¼_expanded`ã€‚
            - `Îµ` æ˜¯éšæœºå™ªå£°ã€‚
            - `T` æ˜¯ä¸€ä¸ªæ¸©åº¦ï¼ˆtemperatureï¼‰è¶…å‚æ•°ã€‚åœ¨æ¨ç†æ—¶ï¼Œé€šè¿‡è°ƒæ•´`T`å¯ä»¥æ§åˆ¶ç”Ÿæˆè¯­éŸ³çš„å¤šæ ·æ€§ã€‚`T` è¶Šå°ï¼Œè¯­éŸ³è¶Šæ¥è¿‘å‡å€¼ï¼Œå˜åŒ–è¶Šå°‘ï¼›`T` è¶Šå¤§ï¼Œéšæœºæ€§è¶Šå¼ºï¼ŒéŸµå¾‹ï¼ˆprosodyï¼‰å˜åŒ–è¶Šä¸°å¯Œã€‚
    3. **è¾“å‡º**: ä¸€ä¸ªéšå˜é‡å¼ é‡ `z`ï¼Œå…¶ç»´åº¦ä¸æœ€ç»ˆçš„æ¢…-å°”é¢‘è°±å›¾ç›¸åŒã€‚
    
    ### æ­¥éª¤ 5: å¹¶è¡Œè§£ç  (Flow-based Decoder)
    
    1. **è¾“å…¥**: æ­¥éª¤4ä¸­ç”Ÿæˆçš„éšå˜é‡ `z`ã€‚
    2. **ç»„ä»¶**: **åŸºäºæµçš„è§£ç å™¨ (Flow-based Decoder)**ï¼Œå®ƒæ˜¯ä¸€ç³»åˆ—å¯é€†çš„è½¬æ¢ï¼ˆInvertible Transformsï¼‰ï¼Œå¦‚ActNormã€Invertible 1x1 Convå’ŒAffine Coupling Layerã€‚
    3. **æ“ä½œ**: è§£ç å™¨æ‰§è¡Œ**é€†å‘è½¬æ¢ï¼ˆinverse transformationï¼‰**ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œè§£ç å™¨å­¦ä¹ å°†çœŸå®çš„æ¢…å°”é¢‘è°±å›¾ `x` æ˜ å°„åˆ°éšå˜é‡ `z`ï¼ˆ`x -> z`ï¼‰ã€‚åœ¨æ¨ç†æ—¶ï¼Œå®ƒæ‰§è¡Œç›¸åçš„æ“ä½œï¼Œå°†é‡‡æ ·çš„éšå˜é‡ `z` æ˜ å°„å›æ¢…å°”é¢‘è°±å›¾ `x`ï¼ˆ`z -> x`ï¼‰ã€‚è¿™ä¸ªè½¬æ¢è¿‡ç¨‹çš„æ¯ä¸€æ­¥éƒ½æ˜¯å¹¶è¡Œè®¡ç®—çš„ã€‚
    4. **è¾“å‡º**: æœ€ç»ˆçš„**æ¢…å°”é¢‘è°±å›¾ (Mel-Spectrogram)**ã€‚
    
    ### æ€»ç»“
    
    Glow-TTSçš„æ¨ç†æµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š
    **æ–‡æœ¬ -> ç¼–ç å™¨ -> (å‡å€¼Î¼, æ—¶é•¿d) -> æ‰©å±•å¯¹é½ -> é‡‡æ ·z -> è§£ç å™¨ -> æ¢…å°”é¢‘è°±å›¾**
    
    è¿™ä¸ªæµç¨‹çš„**ä¼˜ç‚¹**éå¸¸çªå‡ºï¼š
    
    - **å¿«é€Ÿ**: æ•´ä¸ªè¿‡ç¨‹æ²¡æœ‰å¾ªç¯ä¾èµ–ï¼Œå¯ä»¥å®Œå…¨å¹¶è¡ŒåŒ–ï¼Œæ¨ç†é€Ÿåº¦æå¿«ï¼Œå‡ ä¹ä¸è¾“å…¥æ–‡æœ¬é•¿åº¦æ— å…³ï¼ˆåªä¸æœ€é•¿æ–‡æœ¬æœ‰å…³ï¼‰ã€‚
    - **é²æ£’**: ç”±äºä½¿ç”¨äº†ç¡¬å¯¹é½ï¼ˆç”±æ—¶é•¿é¢„æµ‹å™¨å†³å®šï¼‰ï¼Œå®ƒä¸ä¼šåƒåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„è‡ªå›å½’æ¨¡å‹é‚£æ ·åœ¨å¤„ç†é•¿æ–‡æœ¬æˆ–é‡å¤è¯æ—¶å‡ºç°æ³¨æ„åŠ›é”™è¯¯ï¼ˆå¦‚è·³è¯ã€é‡å¤å‘éŸ³ï¼‰ã€‚
    - **å¯æ§**:
        - é€šè¿‡è°ƒæ•´**æ—¶é•¿é¢„æµ‹å™¨**çš„è¾“å‡ºï¼ˆä¾‹å¦‚ï¼Œä¹˜ä»¥ä¸€ä¸ªç³»æ•°ï¼‰ï¼Œå¯ä»¥è½»æ¾æ§åˆ¶è¯­é€Ÿã€‚
        - é€šè¿‡è°ƒæ•´**æ¸©åº¦`T`**ï¼Œå¯ä»¥æ§åˆ¶ç”Ÿæˆè¯­éŸ³çš„éŸµå¾‹å’ŒéŸ³è°ƒå˜åŒ–ã€‚

### Encoder

```
Glow-TTS encoder module.:

    embedding -> <prenet> -> encoder_module -> <postnet> --> h (éšè—è¡¨ç¤ºåºåˆ—) proj_mean
			                                                        |
			                                                        |-> <postnet> -> proj_mean / proj_var
			                                                        |
			                                                        |-> concat -> duration_predictor
		                                                                â†‘
		                                                          speaker_embed
```

- ä¸»è¦æµç¨‹
    
    è¿™ä¸ªç¼–ç å™¨æ¨¡å—çš„æ ¸å¿ƒä»»åŠ¡æ˜¯ï¼š**æ¥æ”¶è¾“å…¥çš„æ–‡æœ¬ï¼ˆéŸ³ç´ åºåˆ—ï¼‰ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªå¯Œå«ä¿¡æ¯çš„éšè—è¡¨ç¤ºï¼Œè¿™ä¸ªè¡¨ç¤ºæ—¢åŒ…å«äº†è¯­éŸ³çš„â€œå†…å®¹â€ä¿¡æ¯ï¼Œä¹ŸåŒ…å«äº†è¯­éŸ³çš„â€œæ—¶é•¿â€ä¿¡æ¯ã€‚** å®ƒçš„è¾“å‡ºæ˜¯åç»­è§£ç æ­¥éª¤çš„åŸºçŸ³ã€‚
    
    ä¸‹é¢æˆ‘ä»¬æŒ‰ç…§æµç¨‹å›¾çš„é¡ºåºä¸€æ­¥æ­¥è§£æï¼š
    
    ---
    
    ### 1. è¾“å…¥ä¸åµŒå…¥ (Input & Embedding)
    
    - **è¾“å…¥ (Input):** ç¼–ç å™¨çš„è¾“å…¥ä¸æ˜¯åŸå§‹çš„æ–‡å­—ï¼ˆå¦‚"hello"ï¼‰ï¼Œè€Œæ˜¯ç»è¿‡é¢„å¤„ç†çš„**éŸ³ç´ åºåˆ— (phoneme sequence)**ã€‚ä¾‹å¦‚ï¼Œæ–‡æœ¬"Glow-TTS"ä¼šè¢«è½¬æ¢æˆä¸€ä¸²éŸ³ç´ IDï¼Œå¦‚ `[jh, l, ow, t, iy, t, iy, eh, s]`ã€‚ä½¿ç”¨éŸ³ç´ å¯ä»¥æ›´å¥½åœ°å¤„ç†æ‹¼å†™ä¸è§„åˆ™çš„å•è¯ï¼Œä½¿æ¨¡å‹å­¦ä¹ æ›´åŠ ç¨³å®šã€‚
    - **åµŒå…¥å±‚ (`embedding`):** è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„åµŒå…¥å±‚ã€‚å®ƒå°†è¾“å…¥çš„ç¦»æ•£éŸ³ç´ IDï¼ˆæ¯”å¦‚æ•´æ•° `[45, 51, 64, ...]`ï¼‰æ˜ å°„æˆè¿ç»­çš„ã€å›ºå®šç»´åº¦çš„å‘é‡ã€‚è¿™ä¸ªå‘é‡å°±æ˜¯éŸ³ç´ çš„åˆå§‹è¡¨ç¤ºã€‚
    
    ### 2. å‰ç½®ç½‘ç»œ (Pre-net)
    
    - **ç»„ä»¶ (`<prenet>`):** åœ¨è¿›å…¥æ ¸å¿ƒçš„Transformeræ¨¡å—ä¹‹å‰ï¼ŒåµŒå…¥å‘é‡ä¼šå…ˆç»è¿‡ä¸€ä¸ªâ€œå‰ç½®ç½‘ç»œâ€ã€‚
    - **ä½œç”¨:** Pre-neté€šå¸¸ç”±å‡ å±‚å·ç§¯å±‚æˆ–å…¨è¿æ¥å±‚æ„æˆï¼Œå¹¶å¸¦æœ‰éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUï¼‰å’ŒDropoutã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å¯¹åµŒå…¥å‘é‡è¿›è¡Œåˆæ­¥çš„ç‰¹å¾æå–å’Œå˜æ¢ï¼Œå¢åŠ æ¨¡å‹çš„éçº¿æ€§èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œä¸ºåç»­çš„å¤æ‚å¤„ç†ï¼ˆè‡ªæ³¨æ„åŠ›ï¼‰å‡†å¤‡ä¸€ä¸ªæ›´å¥½çš„è¾“å…¥è¡¨ç¤ºã€‚
    
    ### 3. æ ¸å¿ƒç¼–ç æ¨¡å— (Encoder Module)
    
    - **ç»„ä»¶ (`encoder_module`):** è¿™æ˜¯ç¼–ç å™¨çš„å¿ƒè„ï¼Œåœ¨Glow-TTSä¸­ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäº**Transformer**çš„ç¼–ç å™¨ã€‚å®ƒç”±å¤šä¸ªç›¸åŒçš„å—å †å è€Œæˆã€‚
    - **ä½œç”¨:** å®ƒçš„æ ¸å¿ƒæ˜¯**è‡ªæ³¨æ„åŠ›æœºåˆ¶ (Self-Attention)**ã€‚å¯¹äºåºåˆ—ä¸­çš„æ¯ä¸€ä¸ªéŸ³ç´ ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ä¼šè®¡ç®—å®ƒä¸åºåˆ—ä¸­æ‰€æœ‰å…¶ä»–éŸ³ç´ çš„å…³è”åº¦ï¼ˆæˆ–ç§°â€œæ³¨æ„åŠ›æƒé‡â€ï¼‰ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•æ‰é•¿è·ç¦»çš„ä¾èµ–å…³ç³»å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹å¯ä»¥ç†è§£åˆ°ï¼Œä¸€ä¸ªéŸ³ç´ çš„å‘éŸ³ä¼šå—åˆ°å…¶å‰åéŸ³ç´ çš„å½±å“ã€‚
    - **è¾“å‡º:** ç»è¿‡è¿™ä¸ªæ¨¡å—å¤„ç†åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªéšè—è¡¨ç¤ºåºåˆ— `h`ã€‚åºåˆ—ä¸­çš„æ¯ä¸€ä¸ªå‘é‡ `h_i` éƒ½ç¼–ç äº†ç¬¬ `i` ä¸ªéŸ³ç´ åŠå…¶ä¸Šä¸‹æ–‡çš„ä¸°å¯Œè¯­è¨€å­¦ä¿¡æ¯ã€‚
    
    ### 4. è¾“å‡ºç”Ÿæˆ (Output Generation)
    
    ä»æ ¸å¿ƒç¼–ç æ¨¡å—è¾“å‡ºçš„éšè—è¡¨ç¤º `h` ä¼šè¢«ç”¨äºç”Ÿæˆä¸¤ä¸ªå…³é”®çš„è¾“å‡ºï¼š
    
    **4.1 å…ˆéªŒåˆ†å¸ƒçš„å‚æ•° (Prior Distribution Parameters)**
    
    - **è·¯å¾„:** `h -> <postnet> -> proj_mean / proj_var`
    - **è§£é‡Š:** è¿™æ¡è·¯å¾„è´Ÿè´£ç”Ÿæˆè¯­éŸ³çš„â€œå†…å®¹â€ã€‚
        - **Post-net (`<postnet>`):** è¿™é‡Œçš„`<postnet>`å¯ä»¥ç†è§£ä¸ºæœ€åçš„çº¿æ€§æŠ•å½±å±‚ã€‚
        - **æŠ•å½± (`proj_mean`, `proj_var`):** éšè—è¡¨ç¤º `h` é€šè¿‡ä¸¤ä¸ªç‹¬ç«‹çš„çº¿æ€§å±‚ï¼Œåˆ†åˆ«é¢„æµ‹å‡ºå…ˆéªŒé«˜æ–¯åˆ†å¸ƒçš„**å‡å€¼ (mean `Î¼`)** å’Œ **æ ‡å‡†å·® (standard deviation `Ïƒ`)**ã€‚ï¼ˆæµç¨‹å›¾ä¸­çš„`proj_var`é€šå¸¸åœ¨å®ç°æ—¶æ˜¯é¢„æµ‹å¯¹æ•°æ ‡å‡†å·® `log Ïƒ`ï¼Œä»¥ä¿è¯å…¶ä¸ºæ­£å¹¶å¢åŠ è®­ç»ƒç¨³å®šæ€§ï¼‰ã€‚
        - **ç»“æœ:** å¯¹äºè¾“å…¥çš„æ¯ä¸€ä¸ªéŸ³ç´ ï¼Œæˆ‘ä»¬éƒ½å¾—åˆ°äº†ä¸€ä¸ªå¯¹åº”çš„ `Î¼_i` å’Œ `Ïƒ_i`ã€‚è¿™ä¸¤ä¸ªå‚æ•°å®šä¹‰äº†åœ¨ç”Ÿæˆè¯­éŸ³æ—¶ï¼Œè¯¥éŸ³ç´ åº”è¯¥ä»å“ªä¸ªé«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ã€‚`Î¼` å†³å®šäº†éŸ³è‰²çš„åŸºæœ¬ç‰¹å¾ã€‚
    
    **4.2 éŸ³ç´ æ—¶é•¿ (Phoneme Duration)**
    
    - **è·¯å¾„:** `h -> concat(h, speaker_embed) -> duration_predictor`
    - **è§£é‡Š:** è¿™æ¡è·¯å¾„è´Ÿè´£ç”Ÿæˆè¯­éŸ³çš„â€œæ—¶é•¿â€**æˆ–**â€œèŠ‚å¥â€ã€‚
        - **è¯´è¯äººåµŒå…¥ (`speaker_embed`):** åœ¨**å¤šè¯´è¯äººï¼ˆmulti-speakerï¼‰æ¨¡å‹ä¸­ï¼Œä¸ºäº†è®©æ¨¡å‹çŸ¥é“è¦ç”¨å“ªä¸ªäººçš„è¯­é€Ÿæ¥è¯´è¯ï¼Œéšè—è¡¨ç¤º `h` ä¼šä¸ä¸€ä¸ªè¯´è¯äººåµŒå…¥å‘é‡ (speaker embedding)** è¿›è¡Œæ‹¼æ¥ï¼ˆ`concat`ï¼‰ã€‚è¿™ä¸ªåµŒå…¥å‘é‡ä»£è¡¨äº†ç‰¹å®šè¯´è¯äººçš„èº«ä»½ç‰¹å¾ï¼ˆåŒ…æ‹¬å¹³å‡è¯­é€Ÿï¼‰ã€‚åœ¨å•è¯´è¯äººæ¨¡å‹ä¸­ï¼Œè¿™ä¸€æ­¥å¯ä»¥çœç•¥ã€‚
        - **æ—¶é•¿é¢„æµ‹å™¨ (`duration_predictor`):** æ‹¼æ¥åçš„å‘é‡è¢«é€å…¥æ—¶é•¿é¢„æµ‹å™¨ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹ç®€å•çš„ç½‘ç»œï¼ˆé€šå¸¸æ˜¯å‡ å±‚å·ç§¯å±‚ï¼‰ï¼Œå®ƒçš„ä»»åŠ¡æ˜¯ä¸ºæ¯ä¸€ä¸ªéŸ³ç´ é¢„æµ‹ä¸€ä¸ªæ ‡é‡å€¼ï¼Œå³è¯¥éŸ³ç´ åº”è¯¥æŒç»­çš„**æ—¶é•¿**ï¼ˆå¯¹åº”å¤šå°‘ä¸ªæ¢…å°”é¢‘è°±å¸§ï¼‰ã€‚
        - **ç»“æœ:** æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæ—¶é•¿åºåˆ— `d`ï¼Œå…¶ä¸­ `d_i` å¯¹åº”ç¬¬ `i` ä¸ªéŸ³ç´ çš„é¢„æµ‹æ—¶é•¿ã€‚
    
    ---
    
    ### æ€»ç»“
    
    Glow-TTSçš„ç¼–ç å™¨è®¾è®¡éå¸¸ç²¾å·§ï¼Œå®ƒå°†å¤æ‚çš„è¯­éŸ³ç”Ÿæˆä»»åŠ¡è§£è€¦ä¸ºä¸¤ä¸ªå­é—®é¢˜ï¼š
    
    1. **â€œè¯´ä»€ä¹ˆå†…å®¹ï¼Ÿâ€** â€”â€” ç”± `Î¼` å’Œ `Ïƒ` å†³å®šï¼Œå®ƒä»¬å®šä¹‰äº†æ¯ä¸ªéŸ³ç´ çš„å£°å­¦ç‰¹å¾ã€‚
    2. **â€œè¯´å¤šé•¿æ—¶é—´ï¼Ÿâ€** â€”â€” ç”± **æ—¶é•¿é¢„æµ‹å™¨** å†³å®šï¼Œå®ƒç¡®å®šäº†æ¯ä¸ªéŸ³ç´ çš„æŒç»­æ—¶é—´ã€‚
    
    è¿™ç§è®¾è®¡ä½¿å¾—Glow-TTSåœ¨æ¨ç†æ—¶å¯ä»¥å…ˆé€šè¿‡**æ—¶é•¿é¢„æµ‹å™¨**ç¡®å®šå¥½å®Œæ•´çš„å¯¹é½å…³ç³»ï¼Œç„¶å**ä¸€æ¬¡æ€§ã€å¹¶è¡Œåœ°**ä»å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·å¹¶è§£ç å‡ºæ•´ä¸ªæ¢…å°”é¢‘è°±å›¾ï¼Œä»è€Œå®ç°äº†æå¿«çš„åˆæˆé€Ÿåº¦å’Œé«˜åº¦çš„é²æ£’æ€§ã€‚
    

### MAS

pass

### Loss

å¥½çš„ï¼ŒGlow-TTSåœ¨è®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°ï¼ˆlossï¼‰ç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«å¯¹åº”æ¨¡å‹è¦å­¦ä¹ çš„ä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼š**ç”Ÿæˆæ­£ç¡®çš„å£°å­¦ç‰¹å¾**å’Œ**é¢„æµ‹æ­£ç¡®çš„éŸ³ç´ æ—¶é•¿**ã€‚

è¿™ä¸¤ä¸ªæŸå¤±åˆ†åˆ«æ˜¯ï¼š

1. **æœ€å¤§ä¼¼ç„¶æŸå¤± (Maximum Likelihood Loss)**
2. **æ—¶é•¿é¢„æµ‹æŸå¤± (Duration Prediction Loss)**
- è¯¦ç»†è§£æè¿™ä¸¤ä¸ªæŸå¤±ã€‚
    
    ### 1. æœ€å¤§ä¼¼ç„¶æŸå¤± (Maximum Likelihood Loss)
    
    è¿™æ˜¯Glow-TTSæ¨¡å‹æœ€æ ¸å¿ƒçš„æŸå¤±ï¼Œç”¨äºè®­ç»ƒ**æ–‡æœ¬ç¼–ç å™¨ï¼ˆEncoderï¼‰å’ŒåŸºäºæµçš„è§£ç å™¨ï¼ˆFlow-based Decoderï¼‰**ã€‚
    
    **ç›®æ ‡ï¼š**Â æœ€å¤§åŒ–ç»™å®šæ–‡æœ¬æ¡ä»¶Â cÂ ä¸‹ï¼Œæ¨¡å‹ç”ŸæˆçœŸå®æ¢…å°”é¢‘è°±å›¾Â xÂ çš„å¯¹æ•°ä¼¼ç„¶æ¦‚ç‡Â log P(x|c)ã€‚
    
    **åŸç†ï¼š**
    
    Glow-TTSæ˜¯ä¸€ä¸ªåŸºäºæµçš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒåˆ©ç”¨äº†**å˜é‡ä»£æ¢å…¬å¼ï¼ˆChange of Variables Formulaï¼‰**ã€‚è§£ç å™¨Â f_decÂ æ˜¯ä¸€ä¸ªå¯é€†å‡½æ•°ï¼Œå¯ä»¥å°†ç®€å•çš„å…ˆéªŒåˆ†å¸ƒï¼ˆå¦‚æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ä¸­çš„éšå˜é‡Â zÂ æ˜ å°„åˆ°å¤æ‚çš„æ•°æ®åˆ†å¸ƒï¼ˆæ¢…å°”é¢‘è°±å›¾Â xï¼‰ã€‚
    
    å…¶å¯¹æ•°ä¼¼ç„¶å¯ä»¥è¡¨ç¤ºä¸ºï¼š
    
    $$
    \log P_X(x|c) = \log P_Z(z|c) + \log \left|\det\frac{\partial f^{-1}_{dec}(x)}{\partial x}\right|
    $$
    
    åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬æ˜¯åå‘è®¡ç®—ï¼Œä»Â $x$Â æ˜ å°„åˆ°Â $z$ï¼ˆ$z = f_{dec}^{-1}(x)$ï¼‰ï¼š
    
    $$
    \log P_X(x|c) = \log P_Z(f_{dec}^{-1}(x)|c) + \log \left|\det\frac{\partial f^{-1}_{dec}(x)}{\partial x}\right|
    $$
    
    è¿™ä¸ªå…¬å¼åŒ…å«ä¸¤é¡¹ï¼š
    
    - ****$\log P_Z(f_{dec}^{-1}(x)|c)$: è¿™ä¸€é¡¹æ˜¯**å…ˆéªŒåˆ†å¸ƒçš„å¯¹æ•°ä¼¼ç„¶**ã€‚
        - é¦–å…ˆï¼Œé€šè¿‡è§£ç å™¨Â f_decÂ çš„é€†å‘ä¼ æ’­ï¼Œå°†çœŸå®çš„æ¢…å°”é¢‘è°±å›¾Â xÂ è½¬æ¢æˆéšå˜é‡Â zã€‚
        - ç„¶åï¼Œé€šè¿‡ç¼–ç å™¨Â f_encÂ å¾—åˆ°å…ˆéªŒåˆ†å¸ƒçš„å‚æ•°Â Î¼Â å’ŒÂ Ïƒã€‚
        - æœ€å…³é”®çš„ä¸€æ­¥æ˜¯ï¼Œ**é€šè¿‡ç‹¬çƒ­å¯¹é½æœç´¢ï¼ˆMASï¼‰ç®—æ³•æ‰¾åˆ°Â zÂ å’ŒÂ (Î¼, Ïƒ)Â ä¹‹é—´æœ€å¯èƒ½çš„å¯¹é½å…³ç³»Â A***ã€‚
        - æœ€åï¼Œè®¡ç®—åœ¨å¯¹é½å…³ç³»Â A*Â ä¸‹ï¼ŒzÂ æœä»ä»¥Â Î¼Â å’ŒÂ ÏƒÂ ä¸ºå‚æ•°çš„é«˜æ–¯åˆ†å¸ƒçš„å¯¹æ•°æ¦‚ç‡ã€‚è¿™éƒ¨åˆ†æŸå¤±ä¼šé©±åŠ¨ç¼–ç å™¨å’Œè§£ç å™¨å­¦ä¹ ç”Ÿæˆæ­£ç¡®çš„å£°å­¦å†…å®¹ã€‚
    - $\log \left|\det\frac{\partial f^{-1}_{dec}(x)}{\partial x}\right|$: è¿™ä¸€é¡¹æ˜¯**é›…å¯æ¯”è¡Œåˆ—å¼çš„å¯¹æ•°å€¼ï¼ˆLog-determinant of Jacobianï¼‰**ã€‚
        - å®ƒè¡¡é‡äº†ä»Â xÂ åˆ°Â zÂ çš„å˜æ¢è¿‡ç¨‹ä¸­ç©ºé—´çš„ç¼©æ”¾ç¨‹åº¦ã€‚
        - å¯¹äºGlowä¸­ä½¿ç”¨çš„æµæ¨¡å‹ç»„ä»¶ï¼ˆå¦‚affine coupling, invertible 1x1 convï¼‰ï¼Œè¿™ä¸€é¡¹å¯ä»¥è¢«é«˜æ•ˆåœ°è®¡ç®—å‡ºæ¥ã€‚
    
    **æœ€ç»ˆçš„ä¼¼ç„¶æŸå¤±å‡½æ•° L_mle å°±æ˜¯æœ€å¤§åŒ–è¿™ä¸ªå¯¹æ•°ä¼¼ç„¶ï¼Œç­‰ä»·äºæœ€å°åŒ–å…¶è´Ÿå€¼ï¼š**
    
    $$
    L_{mle} = - \log P_X(x|c)
    $$
    
    ### 2. æ—¶é•¿é¢„æµ‹æŸå¤± (Duration Prediction Loss)
    
    è¿™ä¸ªæŸå¤±ç”¨äºè®­ç»ƒ**æ—¶é•¿é¢„æµ‹å™¨ï¼ˆDuration Predictorï¼‰**ã€‚
    
    **ç›®æ ‡ï¼š**Â è®©æ—¶é•¿é¢„æµ‹å™¨é¢„æµ‹å‡ºçš„éŸ³ç´ æ—¶é•¿ï¼Œå°½å¯èƒ½åœ°æ¥è¿‘ç”±**ç‹¬çƒ­å¯¹é½æœç´¢ï¼ˆMASï¼‰ç®—æ³•**æ‰¾åˆ°çš„â€œçœŸå®â€æ—¶é•¿ã€‚
    
    **åŸç†ï¼š**
    
    1. **è·å–çœŸå®æ—¶é•¿Â d**: åœ¨æ¯ä¸ªè®­ç»ƒæ­¥ä¸­ï¼ŒMASç®—æ³•ä¼šä¸ºå½“å‰çš„æ–‡æœ¬å’Œè¯­éŸ³å¯¹æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³çš„ç‹¬çƒ­å¯¹é½Â $A^*$ã€‚é€šè¿‡ç»Ÿè®¡æ¯ä¸ªéŸ³ç´ åœ¨è¯¥å¯¹é½ä¸­è¢«åˆ†é…äº†å¤šå°‘ä¸ªæ¢…å°”é¢‘è°±å¸§ï¼Œå°±å¯ä»¥å¾—åˆ°ä¸€ä¸ªâ€œçœŸå®â€çš„æ—¶é•¿åºåˆ—Â dã€‚
        
        $$
        d_i = \sum_j^{T_{mel}} 1_{A^*(j)=i} \qquad (eq.5)
        $$
        
    2. **è·å–é¢„æµ‹æ—¶é•¿Â d_hat**: æ—¶é•¿é¢„æµ‹å™¨æ¥æ”¶ç¼–ç å™¨çš„éšè—è¡¨ç¤ºÂ hï¼Œè¾“å‡ºé¢„æµ‹çš„æ—¶é•¿åºåˆ—Â d_hatã€‚
        
        d_hat = f_dur(sg[f_enc(c)])Â (å…¶ä¸­sgæ˜¯stop-gradient)
        
    3. **è®¡ç®—æŸå¤±Â L_dur**: ä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMean Squared Error, MSEï¼‰æ¥è®¡ç®—é¢„æµ‹æ—¶é•¿å’ŒçœŸå®æ—¶é•¿ä¹‹é—´çš„å·®è·ã€‚é€šå¸¸è¿™ä¸ªè®¡ç®—æ˜¯åœ¨å¯¹æ•°åŸŸï¼ˆlog domainï¼‰è¿›è¡Œçš„ï¼Œå› ä¸ºæ—¶é•¿æ˜¯æ­£æ•°ä¸”åˆ†å¸ƒå¯èƒ½å¾ˆå¹¿ï¼Œåœ¨å¯¹æ•°åŸŸè®¡ç®—å¯ä»¥ä½¿è®­ç»ƒæ›´ç¨³å®šã€‚
        
        L_dur = MSE(log(d_hat), log(d))Â (è®ºæ–‡ä¸­å…¬å¼6çš„ç®€åŒ–å½¢å¼)
        
    
    **ç‰¹åˆ«æ³¨æ„Â stop_gradientÂ æ“ä½œ:**
    
    åœ¨è®¡ç®—Â L_durÂ æ—¶ï¼Œæ—¶é•¿é¢„æµ‹å™¨çš„è¾“å…¥Â f_enc(c)Â è¢«stop_gradientåŒ…è£¹ã€‚è¿™æ„å‘³ç€Â L_durÂ çš„æ¢¯åº¦**ä¸ä¼š**åå‘ä¼ æ’­åˆ°æ–‡æœ¬ç¼–ç å™¨Â f_encã€‚è¿™æ ·åšæ˜¯ä¸ºäº†**è§£è€¦**ä¸¤ä¸ªå­¦ä¹ ä»»åŠ¡ï¼š
    
    - ç¼–ç å™¨çš„ä¸»è¦ä»»åŠ¡æ˜¯å­¦ä¹ å£°å­¦å†…å®¹ï¼Œç”±Â L_mleÂ é©±åŠ¨ã€‚
    - æ—¶é•¿é¢„æµ‹å™¨çš„ä»»åŠ¡æ˜¯å­¦ä¹ èŠ‚å¥ï¼Œç”±Â L_durÂ é©±åŠ¨ã€‚
        
        å¦‚æœä¸åŠ Â stop_gradientï¼Œæ—¶é•¿é¢„æµ‹å™¨çš„è¯¯å·®å¯èƒ½ä¼šâ€œæ±¡æŸ“â€ç¼–ç å™¨ï¼Œä½¿å…¶ä¸ºäº†é™ä½æ—¶é•¿é¢„æµ‹è¯¯å·®è€Œæ”¹å˜å…¶æœ¬åº”å­¦ä¹ çš„å£°å­¦è¡¨ç¤ºï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
        
    
    ---
    
    ### æ€»æŸå¤± (Total Loss)
    
    æœ€ç»ˆï¼ŒGlow-TTSçš„æ€»æŸå¤±æ˜¯è¿™ä¸¤ä¸ªæŸå¤±çš„ç®€å•ç›¸åŠ ï¼ˆæˆ–è€…åŠ æƒç›¸åŠ ï¼Œä½†è®ºæ–‡ä¸­ä¼¼ä¹æ˜¯ç›´æ¥ç›¸åŠ ï¼‰ï¼š
    
    ```
    L_total = L_mle + L_dur
    ```
    
    é€šè¿‡åŒæ—¶ä¼˜åŒ–è¿™ä¸¤ä¸ªæŸå¤±ï¼ŒGlow-TTSæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­ï¼Œæ—¢å­¦ä¹ åˆ°å¦‚ä½•ç”Ÿæˆé«˜è´¨é‡çš„è¯­éŸ³å†…å®¹ï¼Œåˆå­¦ä¹ åˆ°å¦‚ä½•å‡†ç¡®åœ°æ§åˆ¶è¯­éŸ³çš„èŠ‚å¥å’Œæ—¶é•¿ï¼Œå¹¶ä¸”è¿™ä¸ªè¿‡ç¨‹å®Œå…¨ä¸éœ€è¦å¤–éƒ¨å¯¹é½å·¥å…·çš„é¢„å¤„ç†ã€‚
    

### Train

![image.png](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/image%201.png)

- è®­ç»ƒæµç¨‹
    
    å¥½çš„ï¼Œæˆ‘ä»¬æ¥è¯¦ç»†æ¢³ç†ä¸€ä¸‹Glow-TTSçš„å®Œæ•´è®­ç»ƒè¿‡ç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯å…¶èƒ½å¤Ÿæ‘†è„±å¤–éƒ¨å¯¹é½å™¨ã€å®ç°ç«¯åˆ°ç«¯è®­ç»ƒçš„å…³é”®ã€‚
    
    æˆ‘ä»¬å¯ä»¥å°†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹åˆ†è§£ä¸ºåœ¨ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡ï¼ˆbatchï¼‰å†…æ‰§è¡Œçš„å‡ ä¸ªè¿ç»­æ­¥éª¤ã€‚å‚è€ƒè®ºæ–‡ä¸­çš„ **Figure 1(a) An abstract diagram of the training procedure** ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚
    
    ### è®­ç»ƒæµç¨‹ (Step-by-Step for a Single Batch)
    
    å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œæ¯æ¡æ•°æ®åŒ…å«ä¸€å¯¹ **(æ–‡æœ¬åºåˆ— `c`, æ¢…å°”é¢‘è°±å›¾ `x`)**ã€‚
    
    ### æ­¥éª¤ 1: æ­£å‘ä¼ æ’­ (Forward Pass)
    
    1. **æ–‡æœ¬ç¼–ç å™¨ (Encoder) éƒ¨åˆ†:**
        - å°†æ–‡æœ¬åºåˆ— `c`ï¼ˆéŸ³ç´ ï¼‰è¾“å…¥**æ–‡æœ¬ç¼–ç å™¨** (`f_enc`)ã€‚
        - ç¼–ç å™¨è¾“å‡ºä¸¤ä¸ªç»“æœï¼š
            - **éšè—è¡¨ç¤º `h`**: ç”¨äºåç»­çš„æ—¶é•¿é¢„æµ‹ã€‚
            - **å…ˆéªŒåˆ†å¸ƒå‚æ•° (`Î¼`, `Ïƒ`)**: è¿™æ˜¯ä¸€ä¸ªåºåˆ—ï¼Œæ¯ä¸ªéŸ³ç´ å¯¹åº”ä¸€ç»„ `(Î¼_i, Ïƒ_i)`ã€‚è¿™ä¸¤ä¸ªå‚æ•°å®šä¹‰äº†æ¨¡å‹å¯¹æ¯ä¸ªéŸ³ç´ åº”è¯¥å¦‚ä½•å‘éŸ³çš„â€œå…ˆéªŒçŸ¥è¯†â€ã€‚
    2. **æ—¶é•¿é¢„æµ‹å™¨ (Duration Predictor) éƒ¨åˆ†:**
        - å°†ç¼–ç å™¨çš„éšè—è¡¨ç¤º `h` è¾“å…¥**æ—¶é•¿é¢„æµ‹å™¨** (`f_dur`)ã€‚
        - æ—¶é•¿é¢„æµ‹å™¨è¾“å‡ºä¸€ä¸ªé¢„æµ‹çš„**æ—¶é•¿åºåˆ— `d_hat`**ã€‚
        - **æ³¨æ„:** è¿™ä¸€æ­¥çš„è¾“å…¥ `h` è¢« `stop_gradient` åŒ…è£¹ï¼Œè¿™æ„å‘³ç€ä»æ—¶é•¿é¢„æµ‹å™¨äº§ç”Ÿçš„æŸå¤±æ¢¯åº¦ä¸ä¼šå½±å“åˆ°æ–‡æœ¬ç¼–ç å™¨ã€‚
    3. **è§£ç å™¨ (Decoder) éƒ¨åˆ†:**
        - å°†çœŸå®çš„æ¢…å°”é¢‘è°±å›¾ `x` è¾“å…¥**åŸºäºæµçš„è§£ç å™¨** (`f_dec`)ã€‚
        - è§£ç å™¨æ‰§è¡Œ**é€†å‘æ“ä½œ (inverse pass)**ï¼Œå°† `x` è½¬æ¢æˆä¸€ä¸ª**éšå˜é‡ `z`**ã€‚
        - åŒæ—¶ï¼Œè§£ç å™¨è¿˜ä¼šè®¡ç®—**é›…å¯æ¯”è¡Œåˆ—å¼çš„å¯¹æ•°å€¼ (log-determinant of Jacobian)**ï¼Œè¿™æ˜¯è®¡ç®—ä¼¼ç„¶æŸå¤±æ‰€å¿…éœ€çš„ã€‚
    
    è‡³æ­¤ï¼Œæˆ‘ä»¬è·å¾—äº†è®¡ç®—æŸå¤±æ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ï¼š
    
    - å…ˆéªŒåˆ†å¸ƒå‚æ•° `(Î¼, Ïƒ)`
    - é¢„æµ‹æ—¶é•¿ `d_hat`
    - éšå˜é‡ `z`
    - é›…å¯æ¯”è¡Œåˆ—å¼å¯¹æ•°å€¼
    - çœŸå®çš„æ¢…å°”é¢‘è°±å›¾ `x`
    
    ### æ­¥éª¤ 2: ç‹¬çƒ­å¯¹é½æœç´¢ (Monotonic Alignment Search, MAS)
    
    è¿™æ˜¯Glow-TTSè®­ç»ƒè¿‡ç¨‹ä¸­çš„åˆ›æ–°æ ¸å¿ƒã€‚å®ƒåœ¨**æ¯æ¬¡è¿­ä»£**ä¸­åŠ¨æ€åœ°å¯»æ‰¾æœ€ä½³å¯¹é½ã€‚
    
    1. **è¾“å…¥:**
        - è§£ç å™¨è¾“å‡ºçš„éšå˜é‡ `z`ã€‚
        - ç¼–ç å™¨è¾“å‡ºçš„å…ˆéªŒåˆ†å¸ƒå‚æ•° `(Î¼, Ïƒ)`ã€‚
    2. **ç›®æ ‡:** æ‰¾åˆ°ä¸€ä¸ª **ç‹¬çƒ­ï¼ˆmonotonicï¼‰**ä¸” **ä¸è·³è¿‡ï¼ˆsurjectiveï¼‰**çš„å¯¹é½è·¯å¾„ `A*`ï¼Œä½¿å¾—åœ¨è¯¥å¯¹é½ä¸‹ï¼Œéšå˜é‡ `z` çš„å¯¹æ•°ä¼¼ç„¶ `log P(z|c, A)` æœ€å¤§ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ä¸º `z` çš„æ¯ä¸€å¸§æ‰¾åˆ°æœ€åŒ¹é…çš„é‚£ä¸ªéŸ³ç´  `(Î¼_i, Ïƒ_i)`ã€‚
        
        $$
        A := z_j \mapsto c_i
        $$
        
    3. **æ–¹æ³•:** ä½¿ç”¨**åŠ¨æ€è§„åˆ’ (Dynamic Programming)**ï¼Œç±»ä¼¼äºViterbiç®—æ³•ã€‚
        - æ„å»ºä¸€ä¸ªäºŒç»´è¡¨æ ¼ `Q`ï¼Œå…¶ä¸­ `Q[i, j]` è¡¨ç¤ºâ€œå‰ `j` å¸§è¯­éŸ³ (`z_1...z_j`) ä¸å‰ `i` ä¸ªéŸ³ç´  (`c_1...c_i`) å¯¹é½çš„æœ€å¤§å¯¹æ•°ä¼¼ç„¶â€
            
            $$
            Q[i,j] := z_1\cdots z_j \ ä¸\ c_1 \cdots c_i\ å¯¹é½çš„æœ€å¤§ä¼¼ç„¶ = \max_{A}\sum_{k=1}^j\log\mathcal{N}(z_k;\mu_{A(k)},\sigma_{A(k)})
            $$
            
        - é€šè¿‡é€’æ¨å…¬å¼
            
            $$
            Q[i, j] = \max(Q[i-1, j-1], Q[i, j-1]) + \log \mathcal{N}(z_j; Î¼_i, Ïƒ_i) 
            $$
            
            å¡«å……æ•´ä¸ªè¡¨æ ¼ã€‚
            
            åŠ¨æ€è§„åˆ’ï¼Œç›®å‰æ˜¯å¦ç”¨ä¸Šäº†éŸ³ç´  $c_{i}$ (å³ $z_{j-1}$ æ˜¯å¦å±äº $c_i$)
            
            - æ²¡ç”¨ä¸Š $c_{i}$: $Q[i-1, j-1] + \log \mathcal{N}(z_j; Î¼_i, Ïƒ_i)$
            - ç”¨ä¸Šäº† $c_{i}$: $Q[i, j-1] + \log \mathcal{N}(z_j; Î¼_i, Ïƒ_i)$
        - ä»è¡¨æ ¼çš„ç»ˆç‚¹ `Q[T_text, T_mel]` å›æº¯ï¼Œæ‰¾åˆ°æœ€ä½³å¯¹é½è·¯å¾„ `A*`ã€‚
    4. **è¾“å‡º:**
    - **æœ€ä½³å¯¹é½ `A*`**: ä¸€ä¸ªåºåˆ—ï¼ŒæŒ‡æ˜äº† `z` çš„æ¯ä¸€å¸§å¯¹åº”å“ªä¸ªéŸ³ç´ ã€‚
    - **"çœŸå®"æ—¶é•¿ `d`**: é€šè¿‡ç»Ÿè®¡ `A*` ä¸­æ¯ä¸ªéŸ³ç´ å‡ºç°çš„æ¬¡æ•°ï¼Œå¾—åˆ°æ¯ä¸ªéŸ³ç´ çš„â€œçœŸå®â€æ—¶é•¿ã€‚
    
    ### æ­¥éª¤ 3: è®¡ç®—æŸå¤± (Loss Calculation)
    
    ç°åœ¨æˆ‘ä»¬æœ‰äº†æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Œå¯ä»¥è®¡ç®—æ€»æŸå¤±ã€‚
    
    1. **æœ€å¤§ä¼¼ç„¶æŸå¤± (`L_mle`):**
        - ä½¿ç”¨æ­¥éª¤2ä¸­æ‰¾åˆ°çš„æœ€ä½³å¯¹é½ `A*`ï¼Œå°†éšå˜é‡ `z` ä¸å¯¹åº”çš„ `(Î¼, Ïƒ)` é…å¯¹ã€‚
        - è®¡ç®— `z` åœ¨è¿™ä¸ªå¯¹é½ä¸‹çš„**å¯¹æ•°ä¼¼ç„¶**ã€‚
        - åŠ ä¸Šè§£ç å™¨è®¡ç®—å‡ºçš„**é›…å¯æ¯”è¡Œåˆ—å¼å¯¹æ•°å€¼**ã€‚
        - å–è´Ÿæ•°ï¼Œå¾—åˆ° `L_mle`ã€‚è¿™ä¸ªæŸå¤±ä¼šåŒæ—¶ä¼˜åŒ– **ç¼–ç å™¨** å’Œ **è§£ç å™¨**ã€‚
    2. **æ—¶é•¿é¢„æµ‹æŸå¤± (`L_dur`):**
        - ä½¿ç”¨æ­¥éª¤1ä¸­é¢„æµ‹çš„**æ—¶é•¿ `d_hat`** å’Œæ­¥éª¤2ä¸­å¾—åˆ°çš„â€œçœŸå®â€æ—¶é•¿ `d`ã€‚
        - åœ¨å¯¹æ•°åŸŸè®¡ç®—å®ƒä»¬çš„**å‡æ–¹è¯¯å·® (MSE)**ï¼Œå¾—åˆ° `L_dur`ã€‚è¿™ä¸ªæŸå¤±åªä¼˜åŒ–æ—¶é•¿é¢„æµ‹å™¨ã€‚
    3. **æ€»æŸå¤± (`L_total`):**
        - å°†ä¸¤ä¸ªæŸå¤±ç›¸åŠ : `L_total = L_mle + L_dur`ã€‚
    
    ### æ­¥éª¤ 4: åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–° (Backward Pass & Update)
    
    1. **è®¡ç®—æ¢¯åº¦:** å¯¹æ€»æŸå¤± `L_total` è¿›è¡Œåå‘ä¼ æ’­ï¼Œè®¡ç®—æ¨¡å‹ä¸­æ‰€æœ‰å‚æ•°ï¼ˆç¼–ç å™¨ã€è§£ç å™¨ã€æ—¶é•¿é¢„æµ‹å™¨ï¼‰çš„æ¢¯åº¦ã€‚
    2. **æ›´æ–°å‚æ•°:** ä½¿ç”¨ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰æ ¹æ®è®¡ç®—å‡ºçš„æ¢¯åº¦æ›´æ–°æ¨¡å‹çš„æƒé‡ã€‚
    
    ### æ€»ç»“
    
    Glow-TTSçš„è®­ç»ƒæ˜¯ä¸€ä¸ªå·§å¦™çš„è¿­ä»£è¿‡ç¨‹ï¼Œå¯ä»¥çœ‹ä½œæ˜¯**æœŸæœ›æœ€å¤§åŒ– (Expectation-Maximization, EM)** ç®—æ³•æ€æƒ³çš„ä¸€ç§ä½“ç°ï¼š
    
    - **E-Step (æœŸæœ›æ­¥):** åœ¨å›ºå®šçš„æ¨¡å‹å‚æ•°ä¸‹ï¼Œé€šè¿‡**MASç®—æ³•**æ‰¾åˆ°æœ€å¯èƒ½çš„éšå˜é‡ï¼ˆå¯¹é½ `A*`ï¼‰ã€‚
    - **M-Step (æœ€å¤§åŒ–æ­¥):** åœ¨å›ºå®šçš„å¯¹é½ `A*` ä¸‹ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»¥æœ€å¤§åŒ–æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶ï¼ˆå¹¶æœ€å°åŒ–æ—¶é•¿é¢„æµ‹è¯¯å·®ï¼‰ã€‚
    
    è¿™ä¸ªè¿‡ç¨‹ä¸æ–­é‡å¤ï¼Œæ¨¡å‹ä¼šé€æ¸å­¦ä¼šå¦‚ä½•è‡ªå·±æ‰¾åˆ°æ–‡æœ¬å’Œè¯­éŸ³ä¹‹é—´çš„å¯¹é½ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡ä¸”èŠ‚å¥æ­£ç¡®çš„è¯­éŸ³ï¼Œå®Œå…¨æ— éœ€ä»»ä½•å¤–éƒ¨é¢„è®­ç»ƒçš„å¯¹é½æ¨¡å‹ã€‚
    

$L_{mle}$ çš„å€¼å¯ä»¥æ˜¯è´Ÿæ•°ï¼Œå› ä¸ºæ­¤æ—¶çš„ä¼¼ç„¶ $P(x\mid c)$ æ˜¯æ¦‚ç‡å¯†åº¦ï¼Œå› ä¸º mel-spectrogram æ˜¯è¿ç»­å‡½æ•°

### Dataloader

```python
# å®Œæ•´çš„æ•°æ®æµç¨‹ï¼š

# 1. åˆ›å»º DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=4,
    collate_fn=collate_mel_text,  # æŒ‡å®š collate_fn
    shuffle=True
)

# 2. è®­ç»ƒå¾ªç¯
for batch in dataloader:  # ğŸ”¥ è¿™é‡Œè§¦å‘ collate_fn
    # batch å·²ç»æ˜¯å¤„ç†å¥½çš„æ‰¹æ¬¡æ•°æ®
    
    # 3. æ¨¡å‹å¤„ç†
    formatted_batch = model.format_batch(batch)  # ğŸ”¥ è¿™é‡Œè°ƒç”¨ format_batch
    
    # 4. å‰å‘ä¼ æ’­
    outputs = model(formatted_batch)
```

1. **è°ƒç”¨é¡ºåº**:Â Dataset.__getitem__Â â†’Â DataLoaderÂ â†’Â collate_fnÂ â†’Â `model.format_batch`Â â†’Â `model.forward`
2. **collate_fn**: åœ¨ DataLoader è¿­ä»£æ—¶è‡ªåŠ¨è°ƒç”¨ï¼Œå°†å•ä¸ªæ ·æœ¬ç»„åˆæˆæ‰¹æ¬¡
3. **format_batch**: åœ¨æ¨¡å‹çš„ train_step/eval_step ä¸­æ‰‹åŠ¨è°ƒç”¨ï¼Œè¿›ä¸€æ­¥å¤„ç†æ‰¹æ¬¡æ•°æ®

å­˜å‚¨çš„æ•°æ® [B, C, T]

batch ä¸­çš„æ•°æ® [B, C, T]

inference/forward è¾“å‡ºä¸­çš„mel [B, T, C]

dataclass pythonè£…é¥°å™¨

### å…¶ä»–é€‰æ‹©ï¼Ÿ

- Tacotron:Â [paper](https://arxiv.org/abs/1703.10135) âŒ
- Tacotron2:Â [paper](https://arxiv.org/abs/1712.05884) âŒ
- Glow-TTS:Â [paper](https://arxiv.org/abs/2005.11129) âœ…
- Speedy-Speech:Â [paper](https://arxiv.org/abs/2008.03802) â“
- Align-TTS:Â [paper](https://arxiv.org/abs/2003.01950) â“
- FastPitch:Â [paper](https://arxiv.org/pdf/2006.06873.pdf)
    - ç±»ä¼¼ FastSpeech
- FastSpeech:Â [paper](https://arxiv.org/abs/1905.09263)
- FastSpeech2:Â [paper](https://arxiv.org/abs/2006.04558) âŒ
    - åšä¸äº†
- SC-GlowTTS:Â [paper](https://arxiv.org/abs/2104.05557) âŒ
    - GlowTTS çš„ multi-speaker ç‰ˆæœ¬
- Capacitron:Â [paper](https://arxiv.org/abs/1906.03402)
- OverFlow:Â [paper](https://arxiv.org/abs/2211.06892) â“
- Neural HMM TTS:Â [paper](https://arxiv.org/abs/2108.13320) âŒ
    - OverFlow çš„å‰ä½œ
- Delightful TTS:Â [paper](https://arxiv.org/abs/2110.12612)
    - å¾ˆåƒ fastspeech2
- StableTTS âŒ
    - å¤ªæ…¢
- MELLE âŒ
    - æ²¡å¼€æº
- StyleTTS2 â“

![image.png](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/image%202.png)

> from â€œOverFlowâ€
> 

### å°è¯•æ‹Ÿåˆä¸€æ¡æ•°æ®

è®­ç»ƒç”¨çš„ mel-spectrogram

![output1.png](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/output1.png)

æ¨¡å‹ç”Ÿæˆçš„ mel-spectrogram

![output.png](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/output.png)

ç”±è®­ç»ƒæ•°æ®é€šè¿‡ BigVGAN ç”Ÿæˆçš„éŸ³é¢‘

[output1.wav](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/output1.wav)

ç”±ç”Ÿæˆçš„é¢‘è°±å›¾é€šè¿‡ BigVGAN ç”Ÿæˆçš„éŸ³é¢‘

[output.wav](GlowTTS%2022cb1baf8a678027a798c293618a8f5a/output.wav)

åŸºæœ¬èƒ½å¬å‡ºå£°éŸ³ï¼Œä½†æ˜¯ç”µæµå£°å¾ˆå¤§