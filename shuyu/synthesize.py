import torch
from model import GlowTTS
from config import GlowTTSConfig
from tokenizer import ShuTokenizer
import sys
import bigvgan as bigvgan
import soundfile as sf
import yaml

sys.path.append("/home/u-wuhc/backup/bigvgan22HZ")
with open('shupin.yaml', 'r', encoding='utf-8') as file:
    mapping = yaml.safe_load(file)

def convert_text(text):
    converted_text = []
    for char in text:
        if char in mapping:
            converted_text.append(mapping[char])
        else:
            converted_text.append(char)
    return ' '.join(converted_text)

class Load_Bigvgan:
    def __init__(self, model_name="/home/u-wuhc/backup/bigvgan22HZ"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = bigvgan.BigVGAN.from_pretrained(model_name)
        self.model.remove_weight_norm()
        self.model = self.model.eval().to(self.device)
        self.h = self.model.h

    def spectrogram_to_wave(self, spectrogram, path):
        with torch.inference_mode():
            wavgen = self.model(spectrogram)
        wav_gen_float = wavgen.squeeze(0).cpu()
        sf.write(path, wav_gen_float[0].numpy(), self.model.h.sampling_rate)

def load_model_from_checkpoint(checkpoint_path, config=None):
    """ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†"""
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    if config is None:
        config = checkpoint.get('config', None)
        if config is None:
            raise ValueError("æ£€æŸ¥ç‚¹ä¸­æ²¡æœ‰é…ç½®ä¿¡æ¯ï¼Œè¯·æ‰‹åŠ¨æä¾›é…ç½®")
    # config.inference_noise_scale = 0.0  # æ¨ç†æ—¶ä¸ä½¿ç”¨å™ªå£°ç¼©æ”¾
    model = GlowTTS(config)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    model.eval()
    print(f"âœ… æ¨¡å‹å·²ä»æ£€æŸ¥ç‚¹åŠ è½½: {checkpoint_path}")
    print(f"ğŸ“Š æ£€æŸ¥ç‚¹ä¿¡æ¯: æ­¥éª¤ {checkpoint.get('total_steps_done', 'N/A')}, "
          f"Epoch {checkpoint.get('epochs_done', 'N/A')}, "
          f"æŸå¤±: {checkpoint.get('best_loss', 'N/A')}")
    return model, config


def main():
    # å¦‚æœæ£€æŸ¥ç‚¹åŒ…å«é…ç½®ï¼Œåˆ™å¯ä»¥ç›´æ¥åŠ è½½
    checkpoint_path = "./outputs/checkpoint_step_164999.pth" 

    # å¦‚æœæ˜¯ä»…åŒ…å«æ¨¡å‹æƒé‡çš„æ–‡ä»¶ï¼Œè¿˜éœ€è¦æä¾› config
    # checkpoint_path = "./outputs/best_model.pth"  

    config = GlowTTSConfig(
        num_chars=39,
        out_channels=80,
        encoder_type="rel_pos_transformer",
        encoder_params={
            "kernel_size": 3,
            "dropout_p": 0.1,
            "num_layers": 12,
            "num_heads": 8,
            "hidden_channels_ffn": 1024,
            "input_length": None,
        },
        hidden_channels_enc=256,
        hidden_channels_dec=256,
        hidden_channels_dp=400,
        num_flow_blocks_dec=16,
        num_block_layers=6,
    )

    model, config = load_model_from_checkpoint(checkpoint_path, config=config)
    
    text = "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆæ¨¡å‹ã€‚"
    text = convert_text(text)
    print(f"è½¬æ¢åçš„æ–‡æœ¬: {text}")
    tokenizer = ShuTokenizer()
    token_ids = tokenizer(text)
    
    # è½¬æ¢ä¸ºtensor
    text_input = torch.LongTensor(token_ids).unsqueeze(0)  # [1, seq_len]
    text_lengths = torch.LongTensor([len(token_ids)])      # [1]
    
    with torch.no_grad():
        outputs = model.inference(
            x=text_input,
            x_lengths=text_lengths
        )
        mel_spectrogram = outputs["model_outputs"]  # [1, T, C]
        
    print(f"ğŸµ ç”Ÿæˆçš„æ¢…å°”é¢‘è°±å½¢çŠ¶: {mel_spectrogram.shape}")

    vocoder = Load_Bigvgan()
    mel_spectrogram = mel_spectrogram.to(vocoder.device).transpose(1, 2)  # è½¬ç½®ä¸º [1, C, T]
    out_path = "output.wav"
    vocoder.spectrogram_to_wave(mel_spectrogram, out_path)
    print(f"ğŸµ éŸ³é¢‘å·²ä¿å­˜ä¸º {out_path}")

if __name__ == "__main__":
    main()