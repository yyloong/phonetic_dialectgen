import torch
from model import GlowTTS
from config import GlowTTSConfig
from tokenizer import TTSTokenizer
from load_bigvgan import Load_Bigvgan


def load_model_from_checkpoint(checkpoint_path, config=None):
    """ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†"""
    # 1. åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(
        checkpoint_path, map_location="cpu", weights_only=False
    )
    # 2. è·å–é…ç½®ï¼ˆå¦‚æœæ²¡æœ‰æä¾›çš„è¯ï¼‰
    if config is None:
        config = checkpoint.get("config", None)
        if config is None:
            raise ValueError("æ£€æŸ¥ç‚¹ä¸­æ²¡æœ‰é…ç½®ä¿¡æ¯ï¼Œè¯·æ‰‹åŠ¨æä¾›é…ç½®")
    # config.inference_noise_scale = 0.0  # æ¨ç†æ—¶ä¸ä½¿ç”¨å™ªå£°ç¼©æ”¾
    # 3. åˆ›å»ºæ¨¡å‹
    model = GlowTTS(config)
    # 4. åŠ è½½æ¨¡å‹æƒé‡
    if "model_state_dict" in checkpoint:
        model.load_state_dict(checkpoint["model_state_dict"])
    else:
        model.load_state_dict(checkpoint)
    # 5. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    print(f"âœ… æ¨¡å‹å·²ä»æ£€æŸ¥ç‚¹åŠ è½½: {checkpoint_path}")
    print(
        f"ğŸ“Š æ£€æŸ¥ç‚¹ä¿¡æ¯: æ­¥éª¤ {checkpoint.get('total_steps_done', 'N/A')}, "
        f"Epoch {checkpoint.get('epochs_done', 'N/A')}, "
        f"æŸå¤±: {checkpoint.get('best_loss', 'N/A')}"
    )
    return model, config


def main():
    # 1. åŠ è½½æ¨¡å‹

    # å¦‚æœæ£€æŸ¥ç‚¹åŒ…å«é…ç½®ï¼Œåˆ™å¯ä»¥ç›´æ¥åŠ è½½
    # æ··åˆæ¨¡å‹
    checkpoint_path = "./weights/hybrid.pth"
    # æ™®é€šè¯æ¨¡å‹
    # checkpoint_path = "./weights/mandarin.pth"
    # ç²¤è¯­æ¨¡å‹
    # checkpoint_path = "./weights/cantonese.pth"

    # å¦‚æœæ˜¯ä»…åŒ…å«æ¨¡å‹æƒé‡çš„æ–‡ä»¶ï¼Œè¿˜éœ€è¦æä¾› config
    # checkpoint_path = "./outputs/best_model.pth"

    config = GlowTTSConfig(
        num_chars=47,
        out_channels=80,
        # ç¼–ç å™¨å‚æ•°
        encoder_type="rel_pos_transformer",
        encoder_params={
            "kernel_size": 3,
            "dropout_p": 0.1,
            "num_layers": 12,  # ä» 6 å¢åŠ åˆ° 12
            "num_heads": 8,  # ä» 2 å¢åŠ åˆ° 8
            "hidden_channels_ffn": 1024,  # ä» 768 å¢åŠ åˆ° 1024
            "input_length": None,
        },
        # ç¼–ç å™¨éšè—å±‚ - è¿™äº›æ˜¯åˆ†å¼€çš„å‚æ•°
        hidden_channels_enc=256,  # ä» 192 å¢åŠ åˆ° 256
        hidden_channels_dec=256,  # ä» 192 å¢åŠ åˆ° 256
        hidden_channels_dp=400,  # ä» 256 å¢åŠ åˆ° 400
        # Flow å‚æ•°
        num_flow_blocks_dec=16,  # ä» 12 å¢åŠ åˆ° 16
        num_block_layers=6,  # ä» 4 å¢åŠ åˆ° 6
    )

    model, config = load_model_from_checkpoint(checkpoint_path, config=config)

    # 2. å‡†å¤‡è¾“å…¥æ–‡æœ¬
    text = "nÉ›55 pou22 tin22 ieÅ‹35 hÉu35 pei55 hou35 keÅ‹22 ï¼Œ pÉt5 iy21 tsÉu55 mut2 iÉt5 tshÉi21 hÃ¸y33 thÉi35 ï¼Ÿ"
    text = "tÊ‚É¤51 pu51 tian51 iÅ‹215 khou215 pei55 xÉ™n215 paÅ‹51 ï¼Œ pu51 Êu35 tÊ‚ou55 muo51 i55 tÉ•hi215 tÉ•hy51 khan51 ï¼Ÿ"
    text = "nÉ›55 pou22 tin22 ieÅ‹35 hÉu35 pei55 hou35 keÅ‹22 ï¼Œ pu51 Êu35 tÊ‚ou55 muo51 i55 tÉ•hi215 tÉ•hy51 khan51 ï¼Ÿ"

    # 3. æ–‡æœ¬é¢„å¤„ç†
    tokenizer = TTSTokenizer()

    # å°†æ–‡æœ¬è½¬æ¢ä¸ºtokenåºåˆ—
    token_ids = tokenizer(text)

    # è½¬æ¢ä¸ºtensor
    text_input = torch.LongTensor(token_ids).unsqueeze(0)  # [1, seq_len]
    text_lengths = torch.LongTensor([len(token_ids)])  # [1]

    # 4. æ¨ç†
    with torch.no_grad():
        # ç”Ÿæˆè¯­éŸ³
        outputs = model.inference(x=text_input, x_lengths=text_lengths)

        # è·å–æ¢…å°”é¢‘è°±
        mel_spectrogram = outputs["model_outputs"]  # [1, T, C]

    print(f"ğŸµ ç”Ÿæˆçš„æ¢…å°”é¢‘è°±å½¢çŠ¶: {mel_spectrogram.shape}")

    vocoder = Load_Bigvgan()
    mel_spectrogram = mel_spectrogram.to(vocoder.device).transpose(
        1, 2
    )  # è½¬ç½®ä¸º [1, C, T]
    out_path = "output2.wav"
    vocoder.spectrogram_to_wave(mel_spectrogram, out_path)
    print(f"ğŸµ éŸ³é¢‘å·²ä¿å­˜ä¸º {out_path}")


if __name__ == "__main__":
    main()
