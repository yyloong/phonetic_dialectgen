import torch
from config import GlowTTSConfig
from tokenizer import TTSTokenizer
from inference import load_model_from_checkpoint
from load_bigvgan import Load_Bigvgan

def main():
    # 1. åŠ è½½æ¨¡å‹

    # å¦‚æœæ£€æŸ¥ç‚¹åŒ…å«é…ç½®ï¼Œåˆ™å¯ä»¥ç›´æ¥åŠ è½½
    # checkpoint_path = "./outputs/checkpoint_step_129999.pth"  # å‡è®¾è¿™æ˜¯ä½ çš„æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_path = "./outputs/checkpoint_step_139999.pth" 
    # checkpoint_path = "./finetune/checkpoint_step_137999.pth" 

    # æœ€ç»ˆçš„æ™®é€šè¯æ¨¡å‹
    # checkpoint_path = "./weights/mandarin.pth"
    # æœ€ç»ˆçš„ç²¤è¯­æ¨¡å‹
    # checkpoint_path = "./weights/cantonese.pth"

    # å¦‚æœæ˜¯ä»…åŒ…å«æ¨¡å‹æƒé‡çš„æ–‡ä»¶ï¼Œè¿˜éœ€è¦æä¾› config
    # checkpoint_path = "/mnt/nas/shared/datasets/voices/best_model.pth"  # ä½ çš„æ£€æŸ¥ç‚¹è·¯å¾„
    # checkpoint_path = "./weights/best_model.pth"  
    # checkpoint_path = "./outputs/best_model.pth"  
    # checkpoint_path = "./restart/best_model.pth"  # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

    config = GlowTTSConfig(
        num_chars=47,
        out_channels=80,

        # ç¼–ç å™¨å‚æ•°
        encoder_type="rel_pos_transformer",
        encoder_params={
            "kernel_size": 3,
            "dropout_p": 0.1,
            "num_layers": 12,     # ä» 6 å¢åŠ åˆ° 12
            "num_heads": 8,       # ä» 2 å¢åŠ åˆ° 8
            "hidden_channels_ffn": 1024,  # ä» 768 å¢åŠ åˆ° 1024
            "input_length": None,
        },

        # ç¼–ç å™¨éšè—å±‚ - è¿™äº›æ˜¯åˆ†å¼€çš„å‚æ•°
        hidden_channels_enc=256,  # ä» 192 å¢åŠ åˆ° 256
        hidden_channels_dec=256,  # ä» 192 å¢åŠ åˆ° 256 
        hidden_channels_dp=400,   # ä» 256 å¢åŠ åˆ° 400

        # Flow å‚æ•°
        num_flow_blocks_dec=16,   # ä» 12 å¢åŠ åˆ° 16
        num_block_layers=6,       # ä» 4 å¢åŠ åˆ° 6
    )

    model, config = load_model_from_checkpoint(checkpoint_path, config=None)
    
    # 2. å‡†å¤‡è¾“å…¥æ–‡æœ¬
    text = "kÉm55 iÉt2 thai33 iÅ“Å‹21 maÅ‹13 tou33 tsÉÅ‹55 m21 hÉ”i55 Å‹an13 ï¼Œ Å‹É”13 thoÅ‹21 a33 meÅ‹21 tsou35 tsÉu22 iÅ“k3 hou35 hÃ¸y33 thÉi35 kuÉ”35 pou22 tsÃ¸y33 kÉn22 hÉu35 pei55 pau33 tÉÅ‹55 kÉ›33 tin22 ieÅ‹35 ã€‚ Å‹É”13 thÉi21 tshin21 tou33 tsÉ”35 hei33 iyn35 mun21 hÉu35 ã€‚"
    
    # 3. æ–‡æœ¬é¢„å¤„ç†
    tokenizer = TTSTokenizer()
    
    # å°†æ–‡æœ¬è½¬æ¢ä¸ºtokenåºåˆ—
    token_ids = tokenizer(text)
    
    # è½¬æ¢ä¸ºtensor
    text_input = torch.LongTensor(token_ids).unsqueeze(0)  # [1, seq_len]
    text_lengths = torch.LongTensor([len(token_ids)])      # [1]
    
    # 4. æ¨ç†
    with torch.no_grad():
        # ç”Ÿæˆè¯­éŸ³
        outputs = model.inference(
            x=text_input,
            x_lengths=text_lengths
        )
        
        # è·å–æ¢…å°”é¢‘è°±
        mel_spectrogram = outputs["model_outputs"]  # [1, T, C]
        
    print(f"ğŸµ ç”Ÿæˆçš„æ¢…å°”é¢‘è°±å½¢çŠ¶: {mel_spectrogram.shape}")

    vocoder = Load_Bigvgan()
    mel_spectrogram = mel_spectrogram.to(vocoder.device).transpose(1, 2)  # è½¬ç½®ä¸º [1, C, T]
    out_path = "output.wav"
    vocoder.spectrogram_to_wave(mel_spectrogram, out_path)
    print(f"ğŸµ éŸ³é¢‘å·²ä¿å­˜ä¸º {out_path}")

if __name__ == "__main__":
    main()